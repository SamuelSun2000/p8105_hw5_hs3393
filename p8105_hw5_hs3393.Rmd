---
title: "p8105_hw5_hs3393"
author: "Haochen Sun"
date: "2022-11-03"
output: github_document
---

```{r pload packages, message=FALSE}
library(tidyverse)
library(ggplot2)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 8,
  out.width = "70%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1
```{r}
```

## Problem 2
```{r problem 2}
data <- read_csv("data/homicide-data.csv")
head(data)
```

The data describes `r nrow(data)` criminal homicides. The dataset includes the id, report date of homicides, the victims' race, name, gender, age, as well as the place where the homicide happened, specified to city, state, longtitude and latitude. Also, the data despcribes the result of the homicide (whether it is closed and someone is arrested).

```{r, prob2 data manipulation}
casenum <- data %>% 
  janitor::clean_names() %>% 
  unite("city_state", c(city, state), sep = ", ", remove = F) %>%
  mutate(solve = if_else(
    disposition != "Closed by arrest",
    true = "unsolved", false = "solved"
  )) %>% 
  group_by(city_state, solve) %>% 
  summarise(case = n()) %>% 
  pivot_wider(names_from = solve, values_from = case) %>% 
  mutate(total = solved + unsolved)

Baltimore <- filter(casenum, city_state == "Baltimore, MD")

Baltimore_result <- prop.test(Baltimore[["unsolved"]], Baltimore[["total"]]) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

For Baltimore,MD, the estimated proportion of unsolved homicides will be `r round(pull(Baltimore_result, estimate), digits = 4)`, the confidence interval will be `r str_c("(", round(pull(Baltimore_result, conf.low), digits = 4), ",", round(pull(Baltimore_result, conf.high), digits = 4), ")")`.


```{r prop.test for every city}

casenum %>% 
  filter(city_state != "Tulsa, AL") %>% 
  # This is because Tulsa, AL only have 1 sample! Not enough for a proportion test, so just leave it out
  
  mutate(
    prop_test = map2(.x = unsolved, .y = total, ~prop.test(x = .x, n = .y))
    ) %>% 
  mutate(
    prop_test = map(prop_test, broom::tidy)
  ) %>% 
  unnest(prop_test) %>% 
  select(city_state:estimate, conf.low, conf.high) %>%
  ungroup() %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(size = 1) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 1) +
  coord_flip() +
  labs(y = "Estimate proportion", x = "City", title = "Estimated proportion of unsolved homicides in each city")
```

## Problem 3
```{r simulation}
sim_df = 
  expand_grid(
    id = 1:5000,
    mean = 0:6
  ) %>% 
  mutate(
  sets = map(.x = mean, ~rnorm(n = 30, mean = .x, sd = 5 ))
    ) %>% 
  mutate(t_result = map(sets, t.test)) %>% 
  mutate(t_result = map(t_result,  broom::tidy)) %>%
  unnest(t_result) %>% 
  select(id, mean, estimate, p.value)

sim_df %>% 
  mutate(decision = if_else(p.value < 0.05, true = "reject", false = "fail_to_rej")) %>%
  filter(decision == "reject") %>% 
  group_by(mean) %>% 
  summarise(power = n()/5000) %>% 
  ggplot(aes(x = mean, y = power)) + 
  geom_point() + 
  geom_smooth(method = "loess", se = F) +
  labs(x = "True mean", y = "Power", title = "Power of test vs True mean")
  
```

As the true value of $\mu$ increases, the power of test also increases.

```{r simulation2}

plot1 <- sim_df %>% 
  mutate(decision = if_else(p.value < 0.05, true = "reject", false = "fail_to_rej")) %>% 
  group_by(mean) %>% 
  summarise(average = mean(estimate)) %>% 
  ggplot(aes(x = mean, y = average)) +
  geom_point() +
  geom_smooth(method = "loess", se = F) + 
  labs(x = "True Mean", y = "Estimated Mean",
       title = "All Samples")
  


  
plot2 <- sim_df %>% 
  mutate(decision = if_else(p.value < 0.05, true = "reject", false = "fail_to_rej")) %>% 
  filter(decision == "reject") %>% 
  group_by(mean) %>% 
  summarise(
    count = n(),
    rej_average = mean(estimate)) %>% 
  ggplot(aes(x = mean, y = rej_average)) +
  geom_point() +
  geom_smooth(method = "loess", se = F) +
  labs(x = "True Mean", y = "Rejected Samples Estimated Mean",
       title = "Null Rejected Samples")

plot1 + plot2
```

The average of $\hat{\mu}$ in samples for which the null was rejected is not approximately equal to the true $\mu$ when the true $\mu$ is close to the $\mu$ in the null hypothesis. But when the true $\mu$ is not close to the $\mu$ in the null hypothesis, they will be approximately equal.

That is because under this circumstance, the sample distribution have much overlap with the distribution of null hypothesis. Therefore, those samples close to the mean in $H_0$ will not be rejected. Then the distribution of samples for which null was rejected will not be symmetric to the true mean, there will be more samples on the side that are far away from the mean in $H_0$. For example, the mean of the samples for which null was rejected, whose real mean is 1, will be larger than 1. 0 is an exception even though 0 is exactly the same as the mean in $H_0$, because the rejected samples will be those that further away from 0, but these samples contains positive and negative ones and are approximately symmetric to zero, therefore the mean of these samples will be close to 0 (the true mean). 

When the true mean is far from the mean in null hypothesis, nearly all samples will reject $H_0$ so the mean of samples for which the null was rejected will approximately equal to the true value of $\mu$. (In this problem, for example, when true mean is equal to 0).

